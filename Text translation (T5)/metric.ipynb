{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXIZjf12n-A4"
      },
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# -Metric- #\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds.predictions, eval_preds.label_ids\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    return result"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
