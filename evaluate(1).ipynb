{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmBcjHFKlqaK"
      },
      "source": [
        "import torch\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "import nltk\n",
        "device = device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def translate(model, sentence, SRC, TARGET, myTokenizerDE, max_length=50):\n",
        "    model.eval()\n",
        "    src_tokens = SRC.process([myTokenizerDE(sentence)]).to(device)\n",
        "    trg_tokens = [TARGET.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        trg_tensor = torch.LongTensor(trg_tokens).unsqueeze(1).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(src_tokens, trg_tensor)\n",
        "\n",
        "        predicted_token_id = output.argmax(2)[-1].item()\n",
        "\n",
        "        if predicted_token_id == TARGET.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "        trg_tokens.append(predicted_token_id)\n",
        "\n",
        "    translation = [TARGET.vocab.itos[token_id] for token_id in trg_tokens if token_id not in (TARGET.vocab.stoi[\"<sos>\"], TARGET.vocab.stoi[\"<eos>\"], TARGET.vocab.stoi[\"<pad>\"])]\n",
        "\n",
        "    return \" \".join(translation)\n",
        "\n",
        "def evaluate_model(model, test_iterator, SRC, TARGET, myTokenizerDE):\n",
        "    translations = []\n",
        "    reference_sentences = []\n",
        "\n",
        "    for batch in test_iterator:\n",
        "        src = batch.de\n",
        "        trg = batch.en\n",
        "\n",
        "        batch_translations = []\n",
        "        for i in range(src.shape[1]):\n",
        "            source_sentence = ' '.join([SRC.vocab.itos[token] for token in src[:, i]])\n",
        "            translation = translate(model, source_sentence, SRC, TARGET, myTokenizerDE)\n",
        "            batch_translations.append(translation)\n",
        "\n",
        "        translations.extend(batch_translations)\n",
        "        reference_sentences.extend([[' '.join([TARGET.vocab.itos[token] for token in trg[1:, i]])]] for i in range(trg.shape[1]))\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    smoothing = SmoothingFunction().method3\n",
        "    my_corpus_bleu = corpus_bleu(reference_sentences, translations, smoothing_function=smoothing, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "    return my_corpus_bleu"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}