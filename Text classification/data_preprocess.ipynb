{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3VXbWRHRuks"
      },
      "source": [
        "# from config import config\n",
        "import argparse\n",
        "from dataset import IMDbDataset, get_data_loaders, split_data\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import numpy as np\n",
        "\n",
        "# -data_prepocess- #\n",
        "\n",
        "def process_data(data):\n",
        "    reviews = data['processed'].values\n",
        "    words = ' '.join(reviews)\n",
        "    words = words.split()\n",
        "\n",
        "    counter = Counter(words)\n",
        "    vocab = sorted(counter, key=counter.get, reverse=True)\n",
        "    int2word = dict(enumerate(vocab, 1))\n",
        "    int2word[0] = ''  # Assign index 0\n",
        "    word2int = {word: id for id, word in int2word.items()}\n",
        "\n",
        "    return int2word, word2int\n",
        "\n",
        "def pad_features(reviews_enc, pad_token, seq_length=128):\n",
        "    features = np.full((len(reviews_enc), seq_length), pad_token, dtype=int)\n",
        "\n",
        "    for i, row in enumerate(reviews_enc):\n",
        "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features\n",
        "\n",
        "def process_labels(data):\n",
        "    labels = data.label.to_numpy()\n",
        "    return labels\n",
        "\n",
        "def preprocess_data(data, args):\n",
        "    int2word, word2int = process_data(data)\n",
        "    seq_length = args.seq_length\n",
        "\n",
        "    reviews_enc = [[word2int[word] for word in review.split()] for review in tqdm(data['processed'])]\n",
        "    features = pad_features(reviews_enc, pad_token=word2int[''], seq_length=seq_length)\n",
        "\n",
        "    assert len(features) == len(reviews_enc)\n",
        "    assert len(features[0]) == seq_length\n",
        "\n",
        "    labels = process_labels(data)\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "def data_loaders(features, labels, args):\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y = split_data(features, labels, args.train_size, args.val_size)\n",
        "    train_loader, val_loader, test_loader = get_data_loaders(train_x, train_y, val_x, val_y, test_x, test_y, args.batch_size)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
