{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyN64tksR8HvISBloxaLzyxN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5TmKLwO2QjP"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os,gc,re,time\n",
        "import seaborn as sns\n",
        "import spacy,random\n",
        "import re,unicodedata\n",
        "from collections import Counter\n",
        "import warnings,unicodedata\n",
        "import math\n",
        "import torch.optim as optim\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "metadata": {
        "id": "Lk-fxvRt2Xro"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Q4cdy02Yy-",
        "outputId": "add0bea9-3f79-414d-d1c6-7ec5e2ec1695"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfdb64FX2c_f",
        "outputId": "433f72bc-6ee5-4712-887c-9f0d57dfe1ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path_en = \"/content/drive/MyDrive/Colab Notebooks/multi30k/train/train.lc.norm.tok.en.txt\"\n",
        "train_path_de = \"/content/drive/MyDrive/Colab Notebooks/multi30k/train/train.lc.norm.tok.de.txt\"\n",
        "test_path_en = \"/content/drive/MyDrive/Colab Notebooks/multi30k/test/test_2017_flickr.lc.norm.tok.en.txt\"\n",
        "test_path_de = \"/content/drive/MyDrive/Colab Notebooks/multi30k/test/test_2017_flickr.lc.norm.tok.de.txt\""
      ],
      "metadata": {
        "id": "72j-9zbC2e4F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_path_en) as en_raw_train:\n",
        "    en_parsed_train = en_raw_train.readlines()\n",
        "with open(train_path_de) as de_raw_train:\n",
        "    de_parsed_train = de_raw_train.readlines()\n",
        "with open(test_path_en) as en_raw_test:\n",
        "    en_parsed_test = en_raw_test.readlines()\n",
        "with open(test_path_de) as de_raw_test:\n",
        "    de_parsed_test = de_raw_test.readlines()"
      ],
      "metadata": {
        "id": "P34ftDZ7266h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(\"English: {} \\n German: {} \\n\".format(en_parsed_train[i].strip(), de_parsed_train[i].strip()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDRw7xBD28B1",
        "outputId": "a827d7ac-79f4-4452-ba35-9f4411e3d209"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: two young , white males are outside near many bushes . \n",
            " German: zwei junge weiße männer sind im freien in der nähe vieler büsche . \n",
            "\n",
            "English: several men in hard hats are operating a giant pulley system . \n",
            " German: mehrere männer mit schutzhelmen bedienen ein antriebsradsystem . \n",
            "\n",
            "English: a little girl climbing into a wooden playhouse . \n",
            " German: ein kleines mädchen klettert in ein spielhaus aus holz . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_train = [sent.strip().split(\" \") for sent in en_parsed_train]\n",
        "en_test = [sent.strip().split(\" \") for sent in en_parsed_test]\n",
        "de_train = [sent.strip().split(\" \") for sent in de_parsed_train]\n",
        "de_test = [sent.strip().split(\" \") for sent in de_parsed_test]"
      ],
      "metadata": {
        "id": "hFSMMTCC29uo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_index2word = [\"<UNK>\", \"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "de_index2word = [\"<UNK>\", \"<PAD>\", \"<SOS>\", \"<EOS>\"]"
      ],
      "metadata": {
        "id": "ZUhZEUgJ2_dj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ds in [en_train, en_test]:\n",
        "    for sent in ds:\n",
        "        for token in sent:\n",
        "            if token not in en_index2word:\n",
        "                en_index2word.append(token)\n",
        "\n",
        "for ds in [de_train, de_test]:\n",
        "    for sent in ds:\n",
        "        for token in sent:\n",
        "            if token not in de_index2word:\n",
        "                de_index2word.append(token)"
      ],
      "metadata": {
        "id": "hpweQ_qs3DAL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_word2index = {token: idx for idx, token in enumerate(en_index2word)}\n",
        "de_word2index = {token: idx for idx, token in enumerate(de_index2word)}"
      ],
      "metadata": {
        "id": "hz7HO_Ff3EMh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 20"
      ],
      "metadata": {
        "id": "gnBufVup3GH1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_and_pad(vocab, sent, max_length):\n",
        "    sos = [vocab[\"<SOS>\"]]\n",
        "    eos = [vocab[\"<EOS>\"]]\n",
        "    pad = [vocab[\"<PAD>\"]]\n",
        "\n",
        "    if len(sent) < max_length - 2: # -2 for SOS and EOS\n",
        "        n_pads = max_length - 2 - len(sent)\n",
        "        encoded = [vocab[w] for w in sent]\n",
        "        return sos + encoded + eos + pad * n_pads\n",
        "    else: # sent is longer than max_length; truncating\n",
        "        encoded = [vocab[w] for w in sent]\n",
        "        truncated = encoded[:max_length - 2]\n",
        "        return sos + truncated + eos"
      ],
      "metadata": {
        "id": "O2HmmiPC3GPn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_train_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_train]\n",
        "en_test_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_test]\n",
        "de_train_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_train]\n",
        "de_test_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_test]"
      ],
      "metadata": {
        "id": "EWMZjX5m3I-2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_x = np.array(de_train_encoded)\n",
        "train_y = np.array(en_train_encoded)\n",
        "test_x = np.array(de_test_encoded)\n",
        "test_y = np.array(en_test_encoded)\n",
        "\n",
        "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "metadata": {
        "id": "tGk9uU7L3M76"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dl:\n",
        "    source_batch, target_batch = batch\n",
        "\n",
        "    print(f\"첫 번째 배치 크기: {source_batch.shape}\")\n",
        "\n",
        "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
        "    for i in range(source_batch.shape[1]):\n",
        "        print(f\"인덱스 {i}: {source_batch[0][i].item()}\") # 여기에서는 [Seq_num, Seq_len]\n",
        "\n",
        "    # 첫 번째 배치만 확인\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq9qC60m3PC7",
        "outputId": "6caa3201-4c46-4cc7-c135-62b8ddc3e083"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 배치 크기: torch.Size([64, 20])\n",
            "인덱스 0: 2\n",
            "인덱스 1: 4\n",
            "인덱스 2: 7\n",
            "인덱스 3: 59\n",
            "인덱스 4: 10599\n",
            "인덱스 5: 254\n",
            "인덱스 6: 12413\n",
            "인덱스 7: 50\n",
            "인덱스 8: 166\n",
            "인덱스 9: 10342\n",
            "인덱스 10: 9\n",
            "인덱스 11: 273\n",
            "인덱스 12: 117\n",
            "인덱스 13: 16\n",
            "인덱스 14: 3\n",
            "인덱스 15: 1\n",
            "인덱스 16: 1\n",
            "인덱스 17: 1\n",
            "인덱스 18: 1\n",
            "인덱스 19: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "NUcsXuxTwGJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hidden_dim % n_heads == 0\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hidden_dim // n_heads\n",
        "\n",
        "        self.fc_q = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_k = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim]))\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask==0, -1e10)\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        x = x.view(batch_size, -1, self.hidden_dim)\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        return x, attention"
      ],
      "metadata": {
        "id": "TYy1myH73QyL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "T1vEN4_I3YA-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "UB9iw6nZ3ZWO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, encoder_layers, n_heads, pf_dim, dropout_ratio, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio) for i in range(encoder_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim]))\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1)\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # 각 인코더 layer의 출력을 리스트 형태로 저장\n",
        "        encoder_layer_outputs = []\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            encoder_layer_outputs.append(layer(src, src_mask))\n",
        "\n",
        "        return encoder_layer_outputs"
      ],
      "metadata": {
        "id": "PWb9JVzE3jpd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        return trg, attention"
      ],
      "metadata": {
        "id": "OaIRQrrX3luG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, encoder_layers_num, decoder_layers_num, output_dim, hidden_dim, n_heads, pf_dim, dropout_ratio, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_layers_num = encoder_layers_num\n",
        "        self.decoder_layers_num = decoder_layers_num\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio) for i in range(decoder_layers_num)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim]))\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1)\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if i < self.encoder_layers_num:\n",
        "                # 해당 디코더 레이어 i 인덱스를 통해 해당 인코더 레이어의 출력을 선택하여 사용\n",
        "                enc_src_i = enc_src[i]\n",
        "                trg, attention = layer(trg, enc_src_i, trg_mask, src_mask)\n",
        "            else:\n",
        "                # 인코더보다 디코더 레이어가 많아질 경우\n",
        "                # 마지막 인코더 레이어의 출력을 사용\n",
        "                enc_src_last = enc_src[-1]\n",
        "                trg, attention = layer(trg, enc_src_last, trg_mask, src_mask)\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "UDTc3F1U3ngf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len))).bool()\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "1cqfRxcK4Jq4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(de_word2index)\n",
        "OUTPUT_DIM = len(en_word2index)\n",
        "HIDDEN_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 4\n",
        "DEC_HEADS = 4\n",
        "ENC_PF_DIM = 256\n",
        "DEC_PF_DIM = 256\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ],
      "metadata": {
        "id": "84eaevqy4L_0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_PAD_IDX = de_word2index['<PAD>']\n",
        "TRG_PAD_IDX = en_word2index['<PAD>']"
      ],
      "metadata": {
        "id": "AhIyjJIi4Q63"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(3, 3, OUTPUT_DIM, HIDDEN_DIM, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT)\n",
        "\n",
        "# Transformer 객체 선언\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "yUMaGvjv4UVU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z9za17z4WRI",
        "outputId": "31c20b4c-f8d1-48c5-a41b-bf5087e04f41"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(19139, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(10396, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_2): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=10396, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "j94lM5l2v8aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "tGuSQ_abwjdk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        src, trg = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        del src, trg\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "GWP9ualywnW3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "SOmBXfxSwn4g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_dl, optimizer, criterion, CLIP)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CCjKDQLz5Ip",
        "outputId": "3fe91368-e3c0-4bf7-8e58-2034511d5923"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 37s\n",
            "\tTrain Loss: 3.804 | Train PPL: 44.895\n",
            "Epoch: 02 | Time: 1m 37s\n",
            "\tTrain Loss: 2.381 | Train PPL: 10.810\n",
            "Epoch: 03 | Time: 1m 37s\n",
            "\tTrain Loss: 1.825 | Train PPL: 6.201\n",
            "Epoch: 04 | Time: 1m 39s\n",
            "\tTrain Loss: 1.464 | Train PPL: 4.324\n",
            "Epoch: 05 | Time: 1m 39s\n",
            "\tTrain Loss: 1.203 | Train PPL: 3.330\n",
            "Epoch: 06 | Time: 1m 37s\n",
            "\tTrain Loss: 1.003 | Train PPL: 2.726\n",
            "Epoch: 07 | Time: 1m 39s\n",
            "\tTrain Loss: 0.846 | Train PPL: 2.331\n",
            "Epoch: 08 | Time: 1m 38s\n",
            "\tTrain Loss: 0.727 | Train PPL: 2.068\n",
            "Epoch: 09 | Time: 1m 38s\n",
            "\tTrain Loss: 0.637 | Train PPL: 1.890\n",
            "Epoch: 10 | Time: 1m 39s\n",
            "\tTrain Loss: 0.567 | Train PPL: 1.763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate"
      ],
      "metadata": {
        "id": "-vHNH0Kk3uWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, de_word2index, en_word2index, model, max_len=30, logging=True):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # 처음에 'SOS' 토큰, 마지막에 'EOS' 토큰 붙이기\n",
        "    tokens = ['<SOS>'] + tokens + ['<E0S>']\n",
        "    if logging:\n",
        "        print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    src_indexes = [de_word2index.get(token, de_word2index['<UNK>']) for token in tokens]\n",
        "    if logging:\n",
        "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0)\n",
        "\n",
        "    # 소스 문장에 따른 마스크 생성\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 출력 값 구하기\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    # 처음에는 'SOS' 토큰 하나만\n",
        "    trg_indexes = [en_word2index['<SOS>']]\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0)\n",
        "\n",
        "        # 출력 문장에 따른 마스크 생성\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # 출력 문장에서 가장 마지막 단어만 사용\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == en_word2index['<EOS>']:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [en_index2word[i] for i in trg_indexes]\n",
        "\n",
        "    # 첫 번째는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:], attention"
      ],
      "metadata": {
        "id": "TdfrWIP43wc-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(en_path, de_path):\n",
        "\n",
        "    spacy_en = spacy.load('en_core_web_sm')\n",
        "    spacy_de = spacy.load('de_core_news_sm')\n",
        "\n",
        "    with open(en_path) as en_raw_test:\n",
        "        en_parsed_test = en_raw_test.readlines()\n",
        "    with open(de_path) as de_raw_test:\n",
        "        de_parsed_test = de_raw_test.readlines()\n",
        "\n",
        "    en_tokenized = [tokenize_en(line, spacy_en) for line in en_parsed_test]\n",
        "    de_tokenized = [tokenize_de(line, spacy_de) for line in de_parsed_test]\n",
        "\n",
        "    test_df = pd.DataFrame({'en': en_tokenized, 'de': de_tokenized})\n",
        "\n",
        "    return test_df"
      ],
      "metadata": {
        "id": "dg2R_AJd3660"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_de(text, spacy_model):\n",
        "    return [token.text for token in spacy_model(text)]\n",
        "\n",
        "def tokenize_en(text, spacy_model):\n",
        "    return [token.text for token in spacy_model(text)]"
      ],
      "metadata": {
        "id": "jzYwlS5K39bU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = load_and_preprocess_data(test_path_en, test_path_de)"
      ],
      "metadata": {
        "id": "soLKe_yf394C"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['de'][3]"
      ],
      "metadata": {
        "id": "vFqA8SVh3_EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTestData:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "test_data_de = CustomTestData(test['de'])\n",
        "test_data_en = CustomTestData(test['en'])\n",
        "\n",
        "example_idx = 10\n",
        "\n",
        "src = test_data_de[example_idx]\n",
        "trg = test_data_en[example_idx]\n",
        "\n",
        "print(src)\n",
        "print(trg)\n",
        "\n",
        "translation, attention = translate_sentence(src, de_word2index, en_word2index, model, logging=True)\n",
        "\n",
        "print(\"모델 출력 결과:\", \" \".join(translation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqqHYb5f4BZc",
        "outputId": "fc43b711-9aa3-4930-c277-5fe1e29fdeeb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ein', 'junger', 'mann', 'macht', 'auf', 'einem', 'skateboard', 'ein', 'kunststück', 'in', 'der', 'luft', '.', '\\n']\n",
            "['a', 'young', 'man', 'performs', 'an', 'aerial', 'stunt', 'on', 'a', 'skateboard', '.', '\\n']\n",
            "전체 소스 토큰: ['<SOS>', 'ein', 'junger', 'mann', 'macht', 'auf', 'einem', 'skateboard', 'ein', 'kunststück', 'in', 'der', 'luft', '.', '\\n', '<E0S>']\n",
            "소스 문장 인덱스: [2, 21, 180, 29, 270, 34, 30, 420, 21, 581, 11, 12, 725, 16, 0, 0]\n",
            "모델 출력 결과: a young man does a trick on a skateboard in midair doing a trick board underneath a cloudy <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_bleu(data, de_word2index, en_word2index, model, max_len=50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    index = 0\n",
        "\n",
        "    smoothing = SmoothingFunction()\n",
        "\n",
        "    for example_idx in range(1, 1000):\n",
        "        src = test_data_de[example_idx]\n",
        "        trg = test_data_en[example_idx]\n",
        "\n",
        "        pred_trg, _ = translate_sentence(src, de_word2index, en_word2index, model, max_len, logging=False)\n",
        "\n",
        "        # 마지막 토큰 제거\n",
        "        pred_trg = pred_trg[:-1]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "\n",
        "        index += 1\n",
        "        if (index + 1) % 100 == 0:\n",
        "            print(f\"[{index + 1}/{len(data)}]\")\n",
        "            print(f\"예측: {pred_trg}\")\n",
        "            print(f\"정답: {trg}\")\n",
        "\n",
        "    # Calculate BLEU-4 score\n",
        "    bleu_scores = []\n",
        "    for i in range(len(trgs)):\n",
        "        bleu = sentence_bleu(trgs[i], pred_trgs[i], weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing.method0)\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    print(f'Average BLEU-4 Score = {avg_bleu*100:.2f}')"
      ],
      "metadata": {
        "id": "USmv5Xmj4E0a"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_bleu(test_data_de, de_word2index, en_word2index, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS31UBoD4I4O",
        "outputId": "e7c3a2f6-abef-4fc0-e935-3b11b047c146"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100/1000]\n",
            "예측: ['a', 'train', 'rides', 'something', 'through', 'the', 'snow', 'onto', 'something', 'constructed', 'rail', 'frame', '.']\n",
            "정답: ['a', 'train', 'is', 'moving', 'on', 'tracks', 'next', 'to', 'some', 'snow', '.', '\\n']\n",
            "[200/1000]\n",
            "예측: ['man', 'with', 'bicycle', 'selling', 'produce', 'on', 'the', 'street', 'to', 'the', 'saxophone', '.']\n",
            "정답: ['a', 'man', 'with', 'his', 'bicycle', 'selling', 'his', 'products', 'on', 'a', 'street', '\\n']\n",
            "[300/1000]\n",
            "예측: ['the', 'duck', 'flaps', 'its', 'wings', 'of', 'the', 'wet', 'water', 'on', 'the', 'sandy', 'watered', 'read', 'beside', 'the', 'buoy', '.']\n",
            "정답: ['the', 'duck', 'flaps', 'its', 'wings', 'on', 'the', 'wet', 'rocks', 'by', 'the', 'water', '.', '\\n']\n",
            "[400/1000]\n",
            "예측: ['numerous', 'women', 'with', 'tribal', 'garb', 'stand', 'outside', 'a', 'building', 'arch', '.']\n",
            "정답: ['numerous', 'women', 'wearing', 'fur', 'coats', 'are', 'standing', 'outside', 'a', 'building', '.', '\\n']\n",
            "[500/1000]\n",
            "예측: ['a', 'soccer', 'player', 'is', 'being', 'taught', 'as', 'he', 'tries', 'to', 'hit', 'the', 'ball', 'with', 'a', 'pale', 'web', 'displays']\n",
            "정답: ['a', 'soccer', 'player', 'is', 'pushed', 'as', 'he', 'tries', 'to', 'rebound', 'the', 'ball', 'with', 'his', 'head', '.', '\\n']\n",
            "[600/1000]\n",
            "예측: ['a', 'boy', 'dressed', 'in', 'blue', 'and', 'blue', 'uniform', 'is', 'about', 'to', 'kick', 'a', 'soccer', 'ball', '.']\n",
            "정답: ['a', 'boy', 'in', 'blue', 'and', 'white', 'is', 'about', 'to', 'kick', 'a', 'soccer', 'ball', '.', '\\n']\n",
            "[700/1000]\n",
            "예측: ['a', 'little', 'pier', 'overlooking', 'the', 'sea', 'and', 'a', 'couple', 'they', 'stand', 'on', 'the', 'sea', ',', 'the', 'mountains', 'the']\n",
            "정답: ['a', 'small', 'pier', 'showing', 'the', 'sea', 'and', 'some', 'mountains', 'at', 'the', 'end', 'of', 'the', 'landscape', '\\n']\n",
            "[800/1000]\n",
            "예측: ['a', 'good', 'view', 'of', 'a', 'wooden', 'type', 'of', 'green', 'type', 'building', 'with', 'green', 'ground', ',', 'dark', 'buildings', 'in']\n",
            "정답: ['clear', 'view', 'of', 'a', 'reddish', 'desert', 'canyon', ',', 'with', 'a', 'green', 'canyon', 'floor', 'with', 'green', 'trees', ',', 'dark', 'sky', 'background', '.', '\\n']\n",
            "[900/1000]\n",
            "예측: ['a', 'motorcyclist', 'racing', 'a', 'hard', 'hat', 'is', 'racing', 'a', 'corner', 'while', 'spectators', 'read', 'a', 'book', 'in', 'the', 'background']\n",
            "정답: ['a', 'moterbiker', 'is', 'making', 'a', 'sharp', 'turn', 'while', 'in', 'a', 'race', 'with', 'spectators', 'in', 'the', 'background', '.', '\\n']\n",
            "[1000/1000]\n",
            "예측: ['man', 'in', 'gray', 'jacket', 'outside', 'surrounded', 'by', 'red', 'pale', 'flowers', 'stop', 'backdrop', '.']\n",
            "정답: ['man', 'with', 'gray', 'jacket', 'in', 'the', 'grass', 'surrounded', 'by', 'red', 'roses', '\\n']\n",
            "Average BLEU-4 Score = 13.89\n"
          ]
        }
      ]
    }
  ]
}
