{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "poDb5oH3AOJM"
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from preprocess import load_and_preprocess_data, load_data, de_train_dataset, en_train_dataset, de_test_dataset, en_test_dataset\n",
        "from train import run_training_loop\n",
        "from model import Encoder, Decoder, Transformer\n",
        "from preprocess import de_word2index, en_word2index, test\n",
        "import torch.optim as optim\n",
        "from translate import show_bleu, CustomTestData\n",
        "\n",
        "# -Main- #\n",
        "\n",
        "def parse_args():\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Transformer Model for Machine Translation\")\n",
        "    parser.add_argument(\"--train_path_en\", type=str, default=\"path_to_train_en.txt\", help=\"Path to English training data\")\n",
        "    parser.add_argument(\"--train_path_de\", type=str, default=\"path_to_train_de.txt\", help=\"Path to German training data\")\n",
        "    parser.add_argument(\"--max_len\", type=int, default=50, help=\"Maximum translation length\")\n",
        "    parser.add_argument(\"--log_file\", type=str, default=\"transformer.log\", help=\"Log file path\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=0.0005, help=\"Learning rate\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Dataloader batch size\")\n",
        "    parser.add_argument(\"--n_epochs\", type=int, default=2, help=\"Number of training epochs\")\n",
        "    parser.add_argument(\"--clip\", type=float, default=1.0, help=\"Gradient clipping threshold\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    args = parse_args()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    logging.basicConfig(filename=args.log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "    data = load_and_preprocess_data(args.train_path_en, args.train_path_de)\n",
        "\n",
        "    INPUT_DIM = len(de_word2index)\n",
        "    OUTPUT_DIM = len(en_word2index)\n",
        "\n",
        "    HIDDEN_DIM = 256\n",
        "    ENC_LAYERS = 3\n",
        "    DEC_LAYERS = 3\n",
        "    ENC_HEADS = 8\n",
        "    DEC_HEADS = 8\n",
        "    ENC_PF_DIM = 512\n",
        "    DEC_PF_DIM = 512\n",
        "    ENC_DROPOUT = 0.1\n",
        "    DEC_DROPOUT = 0.1\n",
        "\n",
        "    SRC_PAD_IDX = de_word2index['<PAD>']\n",
        "    TRG_PAD_IDX = en_word2index['<PAD>']\n",
        "\n",
        "    enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT)\n",
        "    dec = Decoder(3, 3, OUTPUT_DIM, HIDDEN_DIM, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT)\n",
        "\n",
        "    model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_loader, test_loader = load_data(args.batch_size, de_train_dataset, en_train_dataset, de_test_dataset, en_test_dataset)\n",
        "\n",
        "    run_training_loop(model, train_loader, optimizer, criterion, args)\n",
        "\n",
        "    test_data_de = CustomTestData(test['de'])\n",
        "\n",
        "    show_bleu(test_data_de, de_word2index, en_word2index, model)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}