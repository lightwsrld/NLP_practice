{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKLcZECNSkm8"
      },
      "source": [
        "import argparse\n",
        "import pandas as pd\n",
        "import torch\n",
        "from data_preprocess import preprocess_data, data_loaders\n",
        "from dataset import IMDbDataset, get_data_loaders, split_data\n",
        "from model import TransformerNet, setup_model\n",
        "from train import train_f\n",
        "from test import test_model, test_result\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='argparser')\n",
        "\n",
        "    parser.add_argument(\"--vocab_size\", type=int, default=121302, help=\"Vocabulary size\")\n",
        "    parser.add_argument(\"--embedding_size\", type=int, default=64, help=\"Embedding size\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128, help=\"Batch size\")\n",
        "    parser.add_argument(\"--hidden_size\", type=int, default=768, help=\"Hidden size\")\n",
        "    parser.add_argument(\"--n_heads\", type=int, default=8, help=\"Number of attention heads\")\n",
        "    parser.add_argument(\"--n_layers\", type=int, default=6, help=\"Number of transformer layers\")\n",
        "    parser.add_argument(\"--n_labels\", type=int, default=2, help=\"Number of labels\")\n",
        "    parser.add_argument(\"--dropout\", type=float, default=0.15, help=\"Dropout rate\")\n",
        "    parser.add_argument(\"--seq_length\", type=int, default=256, help=\"Maximum sequence length\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=1e-4, help=\"Learning rate\")\n",
        "    parser.add_argument(\"--grad_clip\", type=float, default=5, help=\"Gradient clipping\")\n",
        "    parser.add_argument(\"--train_size\", type=float, default=0.5, help=\"Training set size\")\n",
        "    parser.add_argument(\"--val_size\", type=float, default=0.5, help=\"Validation set size\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=8, help=\"Number of training epochs\")\n",
        "    parser.add_argument(\"--es_threshold\", type=int, default=3, help=\"Early stopping threshold\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "\n",
        "    data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/transformer/imdb_processed.csv')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    features, labels = preprocess_data(data, args)\n",
        "    model = TransformerNet(args.vocab_size, args.embedding_size, args.hidden_size, args.n_heads, args.n_layers, args.seq_length, args.n_labels, args.dropout).to(device=device)\n",
        "    criterion, optimizer = setup_model(model, args.learning_rate)\n",
        "\n",
        "    train_loader, val_loader, test_loader = data_loaders(features, labels, args)\n",
        "\n",
        "    # Training\n",
        "    train_losses, train_accuracies, val_losses, val_accuracies = train_f(model, optimizer, train_loader, val_loader, criterion, args.epochs, args.es_threshold, args)\n",
        "\n",
        "    # test the model\n",
        "    test_accuracy, test_loss = test_model(model, test_loader, criterion)\n",
        "    test_result(test_accuracy, test_loss)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}