{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP0sYTIbcFnF"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import torchtext\n",
        "import torch\n",
        "import re\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "class DataFrameDataset(torchtext.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, src_field, target_field, is_test=False, **kwargs):\n",
        "        fields = [('de', src_field), ('en', target_field)]\n",
        "        examples = []\n",
        "        for i, row in df.iterrows():\n",
        "            en = row.en\n",
        "            de = row.de\n",
        "            examples.append(torchtext.data.Example.fromlist([de, en], fields))\n",
        "\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "deNLP = spacy.load(\"de_core_news_sm\")\n",
        "deTokenizer = Tokenizer(deNLP.vocab)\n",
        "\n",
        "enNLP = spacy.load('en_core_web_sm')\n",
        "enTokenizer = Tokenizer(enNLP.vocab)\n",
        "\n",
        "def myTokenizerDE(x):\n",
        " return  [word.text for word in\n",
        "          deTokenizer(re.sub(r\"\\s+\\s+\",\" \",re.sub(r\"[\\.\\'\\`\\\"\\r+\\n+]\",\" \",x.lower())).strip())]\n",
        "def myTokenizerEN(x):\n",
        " return  [word.text for word in\n",
        "          enTokenizer(re.sub(r\"\\s+\\s+\",\" \",re.sub(r\"[\\.\\'\\`\\\"\\r+\\n+]\",\" \",x.lower())).strip())]\n",
        "\n",
        "def get_fields():\n",
        "    fixed_length = 200\n",
        "    SRC = torchtext.legacy.data.Field(tokenize=myTokenizerDE, lower=True, batch_first=False, init_token=\"<sos>\", eos_token=\"<eos>\", fix_length=fixed_length)\n",
        "    TARGET = torchtext.legacy.data.Field(tokenize=myTokenizerEN, lower=True, batch_first=False, init_token=\"<sos>\", eos_token=\"<eos>\", fix_length=fixed_length)\n",
        "\n",
        "    return SRC, TARGET\n",
        "\n",
        "def preprocess_data():\n",
        "\n",
        "    train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/WMT2016/train/train.tsv\", sep='\\t')\n",
        "    valid = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/WMT2016/valid/valid.tsv\", sep='\\t')\n",
        "    test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/WMT2016/test/test.tsv\", sep='\\t')\n",
        "\n",
        "    fixed_length = 200\n",
        "    SRC = Field(tokenize=myTokenizerDE, lower=True, batch_first=False, init_token=\"<sos>\", eos_token=\"<eos>\", fix_length=fixed_length)\n",
        "    TARGET = Field(tokenize=myTokenizerEN, lower=True, batch_first=False, init_token=\"<sos>\", eos_token=\"<eos>\", fix_length=fixed_length)\n",
        "\n",
        "    train_dataset = DataFrameDataset(train, SRC, TARGET)\n",
        "    valid_dataset = DataFrameDataset(valid, SRC, TARGET)\n",
        "    test_dataset = DataFrameDataset(test, SRC, TARGET)\n",
        "\n",
        "    SRC.build_vocab(train_dataset, min_freq=2)\n",
        "    TARGET.build_vocab(train_dataset, min_freq=2)\n",
        "\n",
        "    BATCH_SIZE = 8\n",
        "\n",
        "    train_iterator = BucketIterator(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        sort=False,\n",
        "        sort_within_batch=False,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    valid_iterator = BucketIterator(\n",
        "        valid_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        sort=False,\n",
        "        sort_within_batch=False,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_iterator = BucketIterator(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        sort=False,\n",
        "        sort_within_batch=False,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_iterator, valid_iterator, test_iterator, SRC, TARGET"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
