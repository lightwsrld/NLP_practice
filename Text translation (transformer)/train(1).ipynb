{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAeAL2Z3o2bz"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "def train_model(model, train_iterator, optimizer, criterion, trg_vocab_size, device):\n",
        "    loss_track = []\n",
        "    stepLoss = []\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_iterator:\n",
        "        input_sentence = batch.de.to(device)\n",
        "        trg = batch.en.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(input_sentence, trg[:-1])\n",
        "        out = out.reshape(-1, trg_vocab_size)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "        loss = criterion(out, trg)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        stepLoss.append(loss.item())\n",
        "\n",
        "    loss_track.append(np.mean(stepLoss))\n",
        "\n",
        "    return loss_track\n",
        "\n",
        "def valid_model(model, valid_iterator, optimizer, criterion, trg_vocab_size, device):\n",
        "    loss_validation_track = []\n",
        "    stepValidLoss = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in valid_iterator:\n",
        "          input_sentence = batch.de.to(device)\n",
        "          trg = batch.en.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          out = model(input_sentence, trg[:-1])\n",
        "          out = out.reshape(-1, trg_vocab_size)\n",
        "          trg = trg[1:].reshape(-1)\n",
        "          loss = criterion(out, trg)\n",
        "\n",
        "          stepValidLoss.append(loss.item())\n",
        "\n",
        "    loss_validation_track.append(np.mean(stepValidLoss))\n",
        "\n",
        "    return loss_validation_track\n",
        "\n",
        "def train_f(model, train_iterator, valid_iterator, optimizer, criterion, device, checkpoint_dir, epochs, save_frequency, trg_vocab_size):\n",
        "    for e in range(epochs):\n",
        "        if e % 2 == 0:\n",
        "            start_time = time.time()\n",
        "\n",
        "        train_loss = train_model(model, train_iterator, optimizer, criterion, trg_vocab_size, device)\n",
        "        val_loss = valid_model(model, valid_iterator, optimizer, criterion, trg_vocab_size, device)\n",
        "\n",
        "        print(f'Epoch {e + 1}/{epochs}')\n",
        "        print('-' * 10)\n",
        "        print(\"Train Loss at epoch {}: {:.4f}\".format(e + 1, train_loss[0]))\n",
        "        print(\"Valid Loss at epoch {}: {:.4f}\".format(e + 1, val_loss[0]))\n",
        "\n",
        "        if e % 2 == 0:\n",
        "            end_time = time.time()\n",
        "            epoch_time = end_time - start_time\n",
        "            print(\"Time for epoch {}: {:.2f} seconds\".format(e + 1, epoch_time))\n",
        "\n",
        "        if (e + 1) % save_frequency == 0:\n",
        "            checkpoint_name = os.path.join(checkpoint_dir, f'checkpoint_epoch_{e + 1}.pt')\n",
        "            torch.save(model.state_dict(), checkpoint_name)\n",
        "            print(f\"Saved checkpoint for epoch {e + 1} at {checkpoint_name}\")\n",
        "\n",
        "    return train_loss, val_loss\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
